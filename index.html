<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="A programmer&apos;s mind">
<meta name="keywords" content="java c++ python javascript vue">
<meta property="og:type" content="website">
<meta property="og:title" content="Xin&#39;s Blog">
<meta property="og:url" content="http://www.mindincode.com/index.html">
<meta property="og:site_name" content="Xin&#39;s Blog">
<meta property="og:description" content="A programmer&apos;s mind">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Xin&#39;s Blog">
<meta name="twitter:description" content="A programmer&apos;s mind">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://www.mindincode.com/"/>





  <title>Xin's Blog</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Xin's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">I love youbai</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.mindincode.com/2020/12/18/深度学习-编码/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Shaoxin Yin">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xin's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/12/18/深度学习-编码/" itemprop="url">深度学习 Step By Step (二，实战篇)</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-12-18T10:02:00+08:00">
                2020-12-18
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习-DNN-java-python/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习 DNN java  python</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本文将用2种语言来完成上一篇深度神经网络的编码。包括正向的模型预测，以及训练算法。</p>
<h1 id="矩阵运算"><a href="#矩阵运算" class="headerlink" title="矩阵运算"></a>矩阵运算</h1><p>如果你想通过for循环，也不是不可以。对于python而言，矩阵运算已经有很好的库（numpy）了。java我没找到，手写一下，加深对线性代数的理解吧。<br>首先抛开实际问题，专注于矩阵运算。对矩阵的了解对后面极为重要。</p>
<h2 id="向量"><a href="#向量" class="headerlink" title="向量"></a>向量</h2><p>向量是在矩阵之前我们需要了解的，对于之前我们认识的数字，可以成为标量。向量除了有大小，还有方向。如果在二维空间，很好理解，2个数字可以组成一个向量，例如（2，3）。<br>这个向量方可以理解为沿着x轴走2个单位，沿着y轴走3个单位，那么从原点0，到最终点的这一个线段，就是（2，3）所表示的向量，除了距离外，还有一个重要的属性，那就是方向。<br>我们在证明梯度下降最大的方向时候使用的柯西斯瓦茨不等式就是考虑的向量。在实际运用中，特征并不是一个，而是多个特征相互影响，那么这些特征就是一个向量。</p>
<h2 id="矩阵"><a href="#矩阵" class="headerlink" title="矩阵"></a>矩阵</h2><p>在几何意义上，矩阵就是向量的空间变换法则。这里，我们只需记住，权重如果用矩阵来衡量，是最简单不过的。我们只需知道有几行几列。矩阵就是一组有位置的数字。在这里定义矩阵<br>的类，实际上也涵盖了向量。因为我们可以把向量看成是nx1 的矩阵。也就是n行一列（当然也可以认为是1xn，这里统一下，向量用列的多）。</p>
<ul>
<li><p>加法减法<br>两个矩阵必须维度相同。对应位置相加或相减，得到新的矩阵。矩阵内部是一个二维数组。有行与列属性。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Matrix <span class="title">add</span><span class="params">(Matrix m)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">if</span> (m == <span class="keyword">null</span>) &#123;</span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">"matrix can't be null"</span>);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> ((m.row != <span class="keyword">this</span>.row) || (m.column != <span class="keyword">this</span>.column)) &#123;</span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(String.format(<span class="string">"matrix size %sx%s is not fit for size %sx%s"</span>, <span class="keyword">this</span>.row, <span class="keyword">this</span>.column</span><br><span class="line">                  , m.row, m.column));</span><br><span class="line">      &#125;</span><br><span class="line">      Matrix newMatrix = <span class="keyword">new</span> Matrix(row, column);</span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; row; i++) &#123;</span><br><span class="line">          <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; column; j++) &#123;</span><br><span class="line">              newMatrix.data[i][j] = <span class="keyword">this</span>.data[i][j] + m.data[i][j];</span><br><span class="line">          &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">return</span> newMatrix;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>乘法<br>如果乘法中一个是标量，则乘以每一个矩阵中的数，得到一个新的矩阵。<br>如果两个都是矩阵AXB，那么要求A的列必须等于B的行数,最终得到的新矩阵是 A 的行数， B的列数<br>乘法的原则是，A的行上的数乘以对应的B的列上的数，求和后放在A行数所决定的行，B列数所决定的列上。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">  </span><br><span class="line"><span class="function"><span class="keyword">public</span> Matrix <span class="title">multiply</span><span class="params">(Matrix m)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (m == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">"matrix can't be null"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">this</span>.column != m.row) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(String.format(<span class="string">"matrix size %sx%s is not fit for size %sx%s"</span>, <span class="keyword">this</span>.row, <span class="keyword">this</span>.column</span><br><span class="line">                , m.row, m.column));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">final</span> Matrix newMatrix = <span class="keyword">new</span> Matrix(<span class="keyword">this</span>.row, m.column);</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="keyword">this</span>.row; i++) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; m.column; j++) &#123;</span><br><span class="line">            newMatrix.data[i][j] = rowMulColumn(i, j, m);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> newMatrix;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>点乘<br>要求维度一样，对应位置上的数相乘得到新的矩阵。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Matrix <span class="title">multiplyEach</span><span class="params">(Matrix m)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">if</span>(m==<span class="keyword">null</span>)&#123;</span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">"matrix can't be null"</span>);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (<span class="keyword">this</span>.row != m.row || <span class="keyword">this</span>.column != m.column) &#123;</span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(String.format(<span class="string">"matrix size %sx%s is not fit for size %sx%s"</span>, <span class="keyword">this</span>.row, <span class="keyword">this</span>.column</span><br><span class="line">                  , m.row, m.column));</span><br><span class="line">      &#125;</span><br><span class="line">      Matrix newMatrix = <span class="keyword">new</span> Matrix(<span class="keyword">this</span>.row, <span class="keyword">this</span>.column);</span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; row; i++) &#123;</span><br><span class="line">          <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; column; j++) &#123;</span><br><span class="line">              newMatrix.data[i][j] = <span class="keyword">this</span>.data[i][j] * m.data[i][j];</span><br><span class="line">          &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">return</span> newMatrix;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>转置<br>转置就是把每矩阵中一个元素的位置行列对调。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Matrix <span class="title">transpose</span><span class="params">()</span> </span>&#123;</span><br><span class="line">     Matrix matrix = <span class="keyword">new</span> Matrix(column, row);</span><br><span class="line">     <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="keyword">this</span>.row; i++) &#123;</span><br><span class="line">         <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; <span class="keyword">this</span>.column; j++) &#123;</span><br><span class="line">             matrix.data[j][i] = <span class="keyword">this</span>.data[i][j];</span><br><span class="line">         &#125;</span><br><span class="line">     &#125;</span><br><span class="line">     <span class="keyword">return</span> matrix;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>基本上就这些了。其实使用的并不多。逆矩阵这些都没有说到。当然如果有学到卷积神经网络，可能还有个卷积。但是目前用到的基本就这些。<br>对于普通的函数应用，基本对于向量，矩阵来说都是对每个元素都应用函数即可。常见的log，exp等。</p>
<h1 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h1><p>对于权重偏置的初始化， 是一个比较重要的实现环节。虽然对于梯度下降算法，初始“位置”我们不是绝对要求，但是如果一开始就在一个相对不错的位置，<br>是能够加快下降的。这里首相想到一个正态分布（高斯分布）。这是自然界最常见的分布，如果我们的权重按照这个来分布，那么也许是一个不错的选择。<br>使用标准正态分布，均值为0，方差为1<br><img src="/images/normals.png" alt="标准正态分布"><br>关于0对称，方差决定的是图形的胖瘦<br>可以看看其他<br><img src="/images/normal.png" alt="正态分布"><br>绿色是标准正态分布</p>
<p>上代码</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 正态分布 高斯分布</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> u 均值</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> v 方差</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> n 数量</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> 返回指定数量的高斯分布数据</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">double</span>[] randn(<span class="keyword">double</span> u, <span class="keyword">double</span> v, <span class="keyword">int</span> n)&#123;</span><br><span class="line">    <span class="keyword">double</span>[] result = <span class="keyword">new</span> <span class="keyword">double</span>[n];</span><br><span class="line">    java.util.Random random = <span class="keyword">new</span> java.util.Random();</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">        result[i] = v*random.nextGaussian() + u;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>简化下，直接使用标准正态分布</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 均值为0， 方差为1 的标准正态分布</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">double</span>[] randn(<span class="keyword">int</span> n)&#123;</span><br><span class="line">       <span class="keyword">double</span>[] result = <span class="keyword">new</span> <span class="keyword">double</span>[n];</span><br><span class="line">       java.util.Random random = <span class="keyword">new</span> java.util.Random();</span><br><span class="line">       <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">           result[i] = random.nextGaussian();</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="keyword">return</span> result;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>
<p>接下来我们初始化权重，这里需要搞明白的就是，权重是两层神经元之间的连接，那么3层的模型，就有2组权重，也就是总的权重数量是层数减一<br>假设层次是 [4，3，2], 对应的 权重组是 2组，分别是 [(3x4), (2x3)] ，也就是连接下一层作为行，上一层是列。对于python，太简单了</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sizes = [<span class="number">4</span>,<span class="number">3</span>,<span class="number">2</span>]</span><br><span class="line">t = zip(sizes[<span class="number">1</span>:], sizes[:<span class="number">-1</span>])</span><br></pre></td></tr></table></figure>
<p>zip函数把两组数配对，返回一个元组列表。上面的代码就是说sizes一个去尾，一个掐头后组合在一起<br>t=[(3,4),(2,3)]<br>在结合标准正态分布，python的方法可以很简单</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">weights = [np.random.randn(x,y) <span class="keyword">for</span> x,y <span class="keyword">in</span> zip(sizes[<span class="number">1</span>:],sizes[:<span class="number">-1</span>])]</span><br><span class="line">biases = [np.random.randn(y,<span class="number">1</span>) <span class="keyword">for</span> y <span class="keyword">in</span> sizes[<span class="number">1</span>:]]</span><br></pre></td></tr></table></figure>
<p>对于列表的生成，python是很方便。对于偏置，需要注意的是偏置从第二层开始才有。<br>来看看复杂的java代码</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">initBias</span><span class="params">(<span class="keyword">int</span>[] sizes)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//first layer is the input layer, there is no bias</span></span><br><span class="line">    Matrix bias[] = <span class="keyword">new</span> Matrix[sizes.length - <span class="number">1</span>];</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; bias.length; i++) &#123;</span><br><span class="line">        <span class="comment">//bias is n row and 1 column</span></span><br><span class="line">        <span class="keyword">double</span>[] row = Distrubution.randn(sizes[i + <span class="number">1</span>]);</span><br><span class="line">        <span class="keyword">double</span>[][] biasData = <span class="keyword">new</span> <span class="keyword">double</span>[row.length][<span class="number">1</span>];</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; row.length; j++)&#123;</span><br><span class="line">            biasData[j][<span class="number">0</span>] = row[j];</span><br><span class="line">        &#125;</span><br><span class="line">        bias[i] = <span class="keyword">new</span> Matrix(biasData);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">this</span>.bias = bias;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">initWeights</span><span class="params">(<span class="keyword">int</span>[] sizes)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//first layer is the input layer, there is no weight</span></span><br><span class="line">    <span class="comment">//weights may be multi columns</span></span><br><span class="line">    Matrix[] weights = <span class="keyword">new</span> Matrix[sizes.length - <span class="number">1</span>];</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; sizes.length - <span class="number">1</span>; i++) &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span> row = sizes[i+<span class="number">1</span>];</span><br><span class="line">        <span class="keyword">int</span> col = sizes[i];</span><br><span class="line">        <span class="keyword">double</span>[] datas = Distrubution.randn(row * col);</span><br><span class="line">        <span class="keyword">double</span>[][] mdata = <span class="keyword">new</span> <span class="keyword">double</span>[row][col];</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> r = <span class="number">0</span>; r &lt; row; r++) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> c = <span class="number">0</span>; c &lt; col; c++) &#123;</span><br><span class="line">                mdata[r][c] = datas[(r * col) + c];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        weights[i] = <span class="keyword">new</span> Matrix(mdata);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">this</span>.weights = weights;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>不论如何，这里的思想是一致的，python的写法，真的省空间啊。</p>
<h1 id="正向模型"><a href="#正向模型" class="headerlink" title="正向模型"></a>正向模型</h1><p>正向的模型就是预测模型。给一组输入，计算出最终的输出。这里python 真的是更加方便了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">feedforward</span><span class="params">(self,a)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> w, b <span class="keyword">in</span> zip(weights, biases):</span><br><span class="line">        a = sigmoid(np.dot(w,a)+b)</span><br><span class="line">    <span class="keyword">return</span> a</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(z)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1.0</span>/(<span class="number">1.0</span> + np.exp(-z));</span><br></pre></td></tr></table></figure>
<p>太简洁了。激活函数作用下，使用了numpy 的dot方法，dot方法就是矩阵乘法。注意a，是列向量。<br>这时候java中的矩阵操作可以派上用场了</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Matrix <span class="title">sigmoid</span><span class="params">(Matrix z)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> Matrix.exponentOfE(z.multiply(-<span class="number">1</span>)).add(<span class="number">1.0</span>d).divide(<span class="number">1.0</span>d);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> Matrix <span class="title">feedforward</span><span class="params">(Matrix input)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//m is the size of input samples</span></span><br><span class="line">        <span class="keyword">int</span> m = input.getColumn();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; sizes.length - <span class="number">1</span>; i++) &#123;</span><br><span class="line">            input = sigmoid(weight[i].multiply.add(bias[i].extendColumn(m)));</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> input;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Matrix <span class="title">linear</span><span class="params">(Matrix input, Matrix weight)</span> </span>&#123;</span><br><span class="line">          <span class="keyword">return</span> weight.multiply(input);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>java的写法也还凑合。不过这里有些不一样，因为java的写法，是包含了样本数（也就是原来一列的一个样本特征，现在是n列了，可以自己计算下，发现通过矩阵运算，居然最后消失了。但是注意的是偏置不能，所以扩展了一个列，以便计算更加便捷，但是要注意在梯度计算的时候取平均值）。这里通过矩阵操作，我们发现，样本的数量并不会影响计算，但是对于偏置，需要扩展列（每一列都是一个样本）。这里需要注意的，也可以通过单条样本学习，然后通过for循环遍历每一批数据。</p>
<h1 id="随机批量梯度下降算法实现"><a href="#随机批量梯度下降算法实现" class="headerlink" title="随机批量梯度下降算法实现"></a>随机批量梯度下降算法实现</h1><p>第一步，随机，第二步，分批，第三部使用一批数据来实现梯度下降算法。</p>
<p>随机与分批可以同时完成，我们打乱样本，然后根据每一批的大小分批。python非常删除数据列表生成与分片</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#  随机批量梯度下降算法 stochastic grandient descent</span></span><br><span class="line"><span class="comment">#  这里还有 mini-batch</span></span><br><span class="line"><span class="comment">#  完全的微分应用，类似求近似值。使用批量降低难度，通过迭代次数求得精度。</span></span><br><span class="line"><span class="comment">#  注意eta参数，不可过大，也不可太小。</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">SGD</span><span class="params">(self, training_data, epochs, mini_batch_size, eta, test_data=None)</span>:</span></span><br><span class="line">        <span class="string">"""Train the neural network using mini-batch stochastic graident descent. </span></span><br><span class="line"><span class="string">        The "training_data" is a list of tuples "(x, y)" representing the training </span></span><br><span class="line"><span class="string">        inputs and the desired outputs. The other non-optional parameters are self-explanatory.</span></span><br><span class="line"><span class="string">        If "test_data" is provided then the network will be evaluated against the test data </span></span><br><span class="line"><span class="string">        after eache epoch, and partial progress printed out. This is usefull for tracking progress,     but    slows thins down substantially."""</span></span><br><span class="line">        <span class="keyword">if</span> test_data:</span><br><span class="line">            n_test = len(test_data)</span><br><span class="line">        n = len(training_data)</span><br><span class="line">        <span class="comment"># 开始迭代，每一个epoch 完成所有training_data数据学习，并更新参数，通过测试参数来判断学习情况</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(epochs):</span><br><span class="line">            <span class="comment"># 打乱 随机</span></span><br><span class="line">            random.shuffle(training_data)</span><br><span class="line">            <span class="comment"># 根据批量大小从训练数据取出，每一批数据都包含mini_batch_size个训练数据</span></span><br><span class="line">            <span class="comment"># 从一个大数组里分割出n个小数组 ，没个数组里包含mini_batch_size个数据（最后一组不一定）</span></span><br><span class="line">            mini_batches = [training_data[k:k+mini_batch_size] <span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">0</span>, n, mini_batch_size)]</span><br><span class="line">            <span class="keyword">for</span> mini_batch <span class="keyword">in</span> mini_batches:</span><br><span class="line">                self.update_mini_batch(mini_batch, eta)</span><br><span class="line">            <span class="keyword">if</span> test_data:</span><br><span class="line">                print(<span class="string">"Epoch %d: %d/%d"</span>%(j, self.evaluate(test_data), n_test))</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                print(<span class="string">"Epach %d complete"</span>% j)</span><br></pre></td></tr></table></figure>
<p>分批在python里真的很容易。一行代码搞定。</p>
<p>最后是更新参数。这里用到了反向传播，下一节将会详细说明。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_mini_batch</span><span class="params">(self, mini_batch, eta)</span>:</span></span><br><span class="line">        <span class="string">""" Update the network's weights and biases by applying gradient descent using backpropagation to a</span></span><br><span class="line"><span class="string">        single mini batch. The ''mini_batch'' is a list of tuples ''(x,y)'', and ''eta'' is the learning rate.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        nabla_b = [np.zeros(b.shape) <span class="keyword">for</span> b <span class="keyword">in</span> self.biases]</span><br><span class="line">        nabla_w = [np.zeros(w.shape) <span class="keyword">for</span> w <span class="keyword">in</span> self.weights]</span><br><span class="line">        <span class="comment">#遍历每一个训练数据（数据对）</span></span><br><span class="line">        <span class="keyword">for</span> x, y <span class="keyword">in</span> mini_batch:</span><br><span class="line">            <span class="comment"># 通过反向传播算法，得到参数的梯度向量</span></span><br><span class="line">            delta_nabla_b, delta_nabla_w = self.backprop(x,y)</span><br><span class="line"></span><br><span class="line">            nabla_b = [nb+dnb <span class="keyword">for</span> nb, dnb <span class="keyword">in</span> zip(nabla_b, delta_nabla_b)]</span><br><span class="line">            nabla_w = [nw+dnw <span class="keyword">for</span> nw, dnw <span class="keyword">in</span> zip(nabla_w, delta_nabla_w)]</span><br><span class="line">        <span class="comment">#累加每一条数据得到的参数，接下来使用梯度下降算法</span></span><br><span class="line">        <span class="comment">#随机批量梯度下降算法主要是在数据非常多的情况下，我们可以减少计算，加快下降。</span></span><br><span class="line">        <span class="comment"># 考虑到批量的均值，与整体的样本均值 差距不大。这也是我们要做shuffle的原因</span></span><br><span class="line">        <span class="comment"># w` = w - eta/n*nw </span></span><br><span class="line">        self.weights = [w-(eta/len(mini_batch))*nw <span class="keyword">for</span> w, nw <span class="keyword">in</span> zip(self.weights, nabla_w)]</span><br><span class="line">        self.biases = [b-(eta/len(mini_batch))*nb <span class="keyword">for</span> b, nb <span class="keyword">in</span> zip(self.biases, nabla_b)]</span><br></pre></td></tr></table></figure>
<p>这里可以看到 nabla_w 和 nabla_b 都在for循环中不断增加，在最后又要除以每批的大小。这就是求平均值。</p>
<p>我们用java实现时候，权重部分把批量大小带入矩阵，最后自然约去，所以不用求平均值。</p>
<p>来看看java的实现</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">SGD</span><span class="params">(TrainingData trainData, <span class="keyword">int</span> epochs, <span class="keyword">int</span> mini_batch_size, <span class="keyword">double</span> eta, <span class="keyword">double</span> lambda, TrainingData testData)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> testLen = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> trainLen = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">if</span> (testData != <span class="keyword">null</span>) &#123;</span><br><span class="line">            testLen = testData.getSize();</span><br><span class="line">        &#125;</span><br><span class="line">        trainLen = trainData.getSize();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; epochs; i++) &#123;</span><br><span class="line">            <span class="comment">//shuffle training data</span></span><br><span class="line">            trainData.shuffle();</span><br><span class="line">            <span class="comment">//try to get mini batches</span></span><br><span class="line">            <span class="comment">//how to slice the array of Matrix ?</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> k = <span class="number">0</span>; k &lt; trainLen; k += mini_batch_size) &#123;</span><br><span class="line">                <span class="keyword">int</span> to = k + mini_batch_size;</span><br><span class="line">                <span class="keyword">if</span> (k + mini_batch_size &gt; trainLen) &#123;</span><br><span class="line">                    to = trainLen;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">double</span>[][] inputData = Arrays.copyOfRange(trainData.getInput().getData(), k, to);</span><br><span class="line">                <span class="keyword">double</span>[][] resultData = Arrays.copyOfRange(trainData.getOutput().getData(), k, to);</span><br><span class="line"></span><br><span class="line">                <span class="comment">//make a new mini batch training data</span></span><br><span class="line">                updateMiniBatch(<span class="keyword">new</span> TrainingData(inputData, resultData), eta, lambda, trainLen);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (testData != <span class="keyword">null</span>) &#123;</span><br><span class="line">                System.out.println(<span class="string">"Epoch "</span> + i + <span class="string">": "</span> + evaluate(testData) + <span class="string">"\\"</span> + testLen);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                System.out.println(<span class="string">"Epoch complete "</span> + i);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>java的shuffle方法是自定义的。有兴趣的同学可以自己实现</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">swap</span><span class="params">(<span class="keyword">double</span>[][] origin, <span class="keyword">int</span> i, <span class="keyword">int</span> j)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">double</span>[] row = <span class="keyword">new</span> <span class="keyword">double</span>[origin[i].length];</span><br><span class="line">        System.arraycopy(origin[i], <span class="number">0</span>, row, <span class="number">0</span>, row.length);</span><br><span class="line">        System.arraycopy(origin[j], <span class="number">0</span>, origin[i], <span class="number">0</span>, origin[i].length);</span><br><span class="line">        System.arraycopy(row, <span class="number">0</span>, origin[j], <span class="number">0</span>, origin[j].length);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">shuffle</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">double</span>[][] input = <span class="keyword">this</span>.getInput().getData();</span><br><span class="line">        <span class="keyword">double</span>[][] output = <span class="keyword">this</span>.getOutput().getData();</span><br><span class="line">        <span class="comment">//row, the row of input should be the same as output, they represent the features.</span></span><br><span class="line">        <span class="keyword">int</span> len = getSize();</span><br><span class="line">        <span class="comment">// the size of input should be the same as the size of column in output.</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = len; i &gt; <span class="number">0</span>; i--) &#123;</span><br><span class="line">            <span class="comment">//random a item ,swap to the tail which is indicated by i.</span></span><br><span class="line">            <span class="keyword">int</span> randomInt = random.nextInt(i);</span><br><span class="line">            swap(input, randomInt, i - <span class="number">1</span>);</span><br><span class="line">            <span class="comment">//change the output according to input shuffle</span></span><br><span class="line">            swap(output, randomInt, i - <span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (!<span class="keyword">this</span>.isReady()) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">"shuffle "</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>更新权重的方法和python有略微区别。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">updateMiniBatch</span><span class="params">(TrainingData trainingMiniData, <span class="keyword">double</span> eta, <span class="keyword">double</span> lambda, <span class="keyword">double</span> n)</span> </span>&#123;</span><br><span class="line">        Matrix input = trainingMiniData.getInput();</span><br><span class="line">        Matrix output = trainingMiniData.getOutput();</span><br><span class="line">        Parameter params = backprop(input, output, lambda, n, trainingMiniData.getSize());</span><br><span class="line">        <span class="keyword">double</span> len = (<span class="keyword">double</span>)trainingMiniData.getSize();</span><br><span class="line">        <span class="comment">//after back propagation, update the parameters.</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="keyword">this</span>.sizes.length - <span class="number">1</span>; i++) &#123;</span><br><span class="line">            <span class="keyword">this</span>.bias[i] = <span class="keyword">this</span>.bias[i].subtract(params.getBias()[i].colSum().multiply(eta / len));</span><br><span class="line">            <span class="keyword">this</span>.weights[i] = <span class="keyword">this</span>.weights[i].subtract(params.getWeights()[i].multiply(eta/len));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>偏置这里我们有个colSum，这就是把每一列数据相加，合成一列。这个实现也很简单。</p>
<p>这种区别是因为我们把权重和偏置分开了，并使用了矩阵的优势。也可以合起来，合起来的问题是前向传播需要稍微麻烦些。理解起来也不够清晰。有兴趣的同学可以自己尝试。</p>
<p>无论是python还是java我们都有一个方法等待实现， backprop ，也就是反向传播算法。</p>
<h1 id="反向传播算法实现"><a href="#反向传播算法实现" class="headerlink" title="反向传播算法实现"></a>反向传播算法实现</h1><p>反向传播，在理论篇大家已经熟悉了。首相正向计算最后一层，然后计算最后一层误差，然后在计算前一层误差，</p>
<p>只到第二层，在来计算权重和偏置的梯度。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">backprop</span><span class="params">(self, x, y)</span>:</span></span><br><span class="line">        <span class="string">"""Return a tuple ''(nabla_b, nabla_w)'' representing the</span></span><br><span class="line"><span class="string">        gradient for the cost function C_x, ''nabla_b'' and ''nabla_w''</span></span><br><span class="line"><span class="string">        are layer-by-layer lists of numpy arrays, similar to </span></span><br><span class="line"><span class="string">        ''self.biases'' and ''self.weights''. """</span></span><br><span class="line">        nabla_b = [np.zeros(b.shape) <span class="keyword">for</span> b <span class="keyword">in</span> self.biases]</span><br><span class="line">        nabla_w = [np.zeros(w.shape) <span class="keyword">for</span> w <span class="keyword">in</span> self.weights]</span><br><span class="line">        <span class="comment">#feedforward</span></span><br><span class="line">        activation = x</span><br><span class="line">        activations=[x] <span class="comment">#list to store all the activations, layer by layer</span></span><br><span class="line">        zs = [] <span class="comment">#list to store all the z vectors layer by layer</span></span><br><span class="line">        <span class="keyword">for</span> b, w <span class="keyword">in</span> zip(self.biases, self.weights):</span><br><span class="line">            z = np.dot(w, activation)+b</span><br><span class="line">            zs.append(z)</span><br><span class="line">            activation = Network.sigmoid(z)</span><br><span class="line">            activations.append(activation)</span><br><span class="line">        <span class="comment">#backward pass</span></span><br><span class="line">        <span class="comment">#输出层与其输入的误差计算</span></span><br><span class="line">        delta = (self.cost).delta(zs[<span class="number">-1</span>],activations[<span class="number">-1</span>],y)</span><br><span class="line">        nabla_b[<span class="number">-1</span>] =delta</span><br><span class="line">        nabla_w[<span class="number">-1</span>] = np.dot(delta, activations[<span class="number">-2</span>].transpose())</span><br><span class="line">        <span class="comment"># 开始倒数第二层一直到正数第二层，求误差</span></span><br><span class="line">        <span class="keyword">for</span> l <span class="keyword">in</span> range(<span class="number">2</span>, self.num_layers):</span><br><span class="line">            z = zs[-l]</span><br><span class="line">            sp = Network.sigmoid_prime(z)</span><br><span class="line">            delta = np.dot(self.weights[-l+<span class="number">1</span>].transpose(), delta)*sp</span><br><span class="line">            nabla_b[-l] = delta</span><br><span class="line">            nabla_w[-l] = np.dot(delta, activations[-l<span class="number">-1</span>].transpose())</span><br><span class="line">        <span class="keyword">return</span> (nabla_b, nabla_w)</span><br></pre></td></tr></table></figure>
<p>具体编码的时候，我们就设计到代价函数的选择，激活函数，以及激活函数的导数等。如果理论没有忘记，这里很好理解。这里把每一层的结果都存在了activations数组中。delta函数就是激活函数求导。这里for语句反向计算误差的方法利用了python的反向索引，负号来实现，很是精妙。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 激活函数 np.exp是自然对数， python天生支持向量操作啊</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(z)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> (<span class="number">1.0</span>/(<span class="number">1.0</span> + np.exp(-z)))</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid_prime</span><span class="params">(z)</span>:</span></span><br><span class="line">        <span class="string">""" 这是对激活函数求导"""</span></span><br><span class="line">        <span class="keyword">return</span> Network.sigmoid(z)*(<span class="number">1</span>-Network.sigmoid(z))</span><br></pre></td></tr></table></figure>
<p>虽然二次代价函数不经常使用，我们这里还是给出两种代价函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QuadraticCost</span><span class="params">(object)</span>:</span></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fn</span><span class="params">(a, y)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">0.5</span>*np.linalg.norm(a-y)**<span class="number">2</span></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">delta</span><span class="params">(z, a, y)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> (a-y) * Network.sigmoid_prime(z)</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CrossEntropyCost</span><span class="params">(object)</span>:</span></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fn</span><span class="params">(a, y)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> np.sum(np.nan_to_num(-y*np.log(a)-(<span class="number">1</span>-y)*np.log(<span class="number">1</span>-a))) </span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">delta</span><span class="params">(z, a, y)</span>:</span></span><br><span class="line">        <span class="string">""" 为了函数接口一致，z虽然没用到，也作为参数 """</span></span><br><span class="line">        <span class="keyword">return</span> (a-y)</span><br></pre></td></tr></table></figure>
<p>这里numpy库为我们提供了线性代数模块linalg， normal是求范数，默认二范数，就是整体求平方和开根号。</p>
<p>nan_to_num是避免出现nan类型，用0替代。</p>
<p>来看看java的代码实现，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> Parameter <span class="title">backprop</span><span class="params">(Matrix input, Matrix output, <span class="keyword">double</span> lambda, <span class="keyword">double</span> n, <span class="keyword">int</span> m)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//a row is a sample input data, need make a column is a sample input data, so column is the size of samples</span></span><br><span class="line">        Matrix activation = input.transpose();</span><br><span class="line">        output = output.transpose();</span><br><span class="line">        <span class="keyword">int</span> layer = <span class="keyword">this</span>.sizes.length;</span><br><span class="line">        Matrix detBias[] = <span class="keyword">new</span> Matrix[<span class="keyword">this</span>.bias.length];</span><br><span class="line">        Matrix detWeights[] = <span class="keyword">new</span> Matrix[<span class="keyword">this</span>.weights.length];</span><br><span class="line">        Matrix[] activations = <span class="keyword">new</span> Matrix[layer];</span><br><span class="line">        activations[<span class="number">0</span>] = Matrix.copy(activation);</span><br><span class="line">        Matrix[] layerWithInput = <span class="keyword">new</span> Matrix[layer - <span class="number">1</span>];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; layer - <span class="number">1</span>; i++) &#123;</span><br><span class="line">            <span class="keyword">int</span> batchSize = activation.getColumn();</span><br><span class="line">            Matrix z = linear(activation, <span class="keyword">this</span>.weights[i]).add(bias[i].extendColumn(batchSize));</span><br><span class="line">            layerWithInput[i] = z;</span><br><span class="line">            activation = sigmoid(z);</span><br><span class="line">            activations[i+<span class="number">1</span>] = activation;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        Matrix lastLayerOutput = activations[layer-<span class="number">1</span>];</span><br><span class="line"></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * according  to the back propagation, the last error is computed by</span></span><br><span class="line"><span class="comment">         * the following method</span></span><br><span class="line"><span class="comment">         * e[L] = (dC/da).d(sigmoid)</span></span><br><span class="line"><span class="comment">         * if we use the quadratic function as cost function, the derivative is</span></span><br><span class="line"><span class="comment">         * a[L] - Y</span></span><br><span class="line"><span class="comment">         * here the Y is the real result</span></span><br><span class="line"><span class="comment">         * */</span></span><br><span class="line">        Matrix errors = <span class="keyword">this</span>.cost.derivative(layerWithInput[layer-<span class="number">2</span>], lastLayerOutput, output);</span><br><span class="line">        detBias[detBias.length-<span class="number">1</span>] = Matrix.copy(errors);</span><br><span class="line">        detWeights[detWeights.length-<span class="number">1</span>] =  errors.multiply(activations[layer-<span class="number">2</span>].transpose());</span><br><span class="line"></span><br><span class="line">        <span class="comment">/** the error of last layer  has been computed.</span></span><br><span class="line"><span class="comment">         *  so layer - 3 is the second error in reversed-order</span></span><br><span class="line"><span class="comment">         **/</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = layer - <span class="number">3</span>; i &gt;= <span class="number">0</span>; i--) &#123;</span><br><span class="line"><span class="comment">//</span></span><br><span class="line">            errors = weights[i+<span class="number">1</span>].transpose().multiply(errors).multiplyEach(costPrime(layerWithInput[i]));</span><br><span class="line">            detBias[i] = Matrix.copy(errors);</span><br><span class="line">            detWeights[i] = errors.multiply(activations[i].transpose());</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//set bias and weights</span></span><br><span class="line">        Parameter parameter = <span class="keyword">new</span> Parameter();</span><br><span class="line">        parameter.setBias(detBias);</span><br><span class="line">        parameter.setWeights(detWeights);</span><br><span class="line">        <span class="keyword">return</span> parameter;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>这里需要注意的是，程序语言的数组开始是0， 理论中是从1开始。所以这里要注意。</p>
<p>对于n层的神经网络，将会有n-1个输入，n-1个权重矩阵，n-1个误差。这些细节是要注意的。</p>
<p>交叉熵的java实现</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CrossEntropyCost</span> <span class="keyword">implements</span> <span class="title">CostFunction</span></span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">func</span><span class="params">(Matrix a, Matrix y)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> a.multiply(-<span class="number">1</span>).multiplyEach(a.log()).subtract(y.subtractBy(<span class="number">1</span>).multiplyEach(a.subtractBy(<span class="number">1</span>).log())).sum();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Matrix <span class="title">derivative</span><span class="params">(Matrix z, Matrix a, Matrix y)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> a.subtract(y);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>至此，一个基本的深度神经网络系统就可以使用了。然后找个项目来试验下。</p>
<h1 id="手写数字识别"><a href="#手写数字识别" class="headerlink" title="手写数字识别"></a>手写数字识别</h1><p>MNIST这个手写数字库，真的是非常的好用，不大不小。感谢Yann.Lecun</p>
<p>我们可以从这里下载  <img src="http://yann.lecun.com/exdb/mnist/" alt="MNIST"></p>
<p>MNIST 数据集是基于 NIST（美国国家标准与技术研究院）收集的两个数据集合。为了构建 MNIST，</p>
<p>NIST 数据集合被 Yann LeCun，Corinna Cortes 和 Christopher J. C. Burges 拆分放⼊⼀个更⽅便的格式。</p>
<p>MNIST的数据是描述的28x28像素的图片，每一个图片都是一个手写数字。这些数字来源不同的人。我们分成了两部分</p>
<p>一部分用来训练，一部分用来测试。大概一共有60000个训练数据集，包括他的label（也就是正确的分类）。</p>
<p>如果细心的同学会发现，我们的java代码z红的trainingData  在使用的时候，做了转置操作。这是因为我们把数据读取到了一行中。通过转置，行变成了列，而我们的理论都是基于列来推理的。</p>
<p>先看看如何读取这些数据。 对于训练数据train-images-idx3-ubyte</p>
<p>[offset] [type]          [value]          [description]<br>0000     32 bit integer  0x00000803(2051) magic number<br>0004     32 bit integer  60000            number of images<br>0008     32 bit integer  28               number of rows<br>0012     32 bit integer  28               number of columns<br>0016     unsigned byte   ??               pixel<br>0017     unsigned byte   ??               pixel<br>……..<br>xxxx     unsigned byte   ??               pixel</p>
<p>Pixels are organized row-wise. Pixel values are 0 to 255. 0 means background (white), 255 means foreground (black).</p>
<p>数据开头的4个字节是magicnumber，然后的4个字节是int型的总的图片数量，然后的4个字节是row，再后面的是column数， 这样我们可以通过row x column得出一张图片的所需字节数。这里是 28 x 28 = 784</p>
<p>数值是从0-255的灰度表示0表示白色，255是黑色.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment">//一张图片就是一行，这里会把图片的二位数组形式转换为一维数组</span></span><br><span class="line">    <span class="comment">//例如28*28的图片，展开变成1*784的数组。</span></span><br><span class="line">    <span class="comment">//做了scalling</span></span><br><span class="line">    <span class="comment">//数据来源 http://yann.lecun.com/exdb/mnist/</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">double</span>[][] readFeatruesFromFile(String fileName) <span class="keyword">throws</span> Exception&#123;</span><br><span class="line">       FileInputStream fin = <span class="keyword">new</span> FileInputStream(fileName);</span><br><span class="line">       <span class="keyword">if</span>(fin != <span class="keyword">null</span>)&#123;</span><br><span class="line">            BufferedInputStream bufIns = <span class="keyword">new</span> BufferedInputStream(fin);</span><br><span class="line">            <span class="keyword">byte</span>[] header = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">16</span>];</span><br><span class="line">            bufIns.read(header,<span class="number">0</span>,header.length);</span><br><span class="line"></span><br><span class="line">            <span class="keyword">int</span> magic = byte2Int(header,<span class="number">0</span>);</span><br><span class="line">            <span class="keyword">int</span> row = byte2Int(header, <span class="number">8</span>);</span><br><span class="line">            <span class="keyword">int</span> col = byte2Int(header,<span class="number">12</span>);</span><br><span class="line">            <span class="keyword">int</span> size = byte2Int(header,<span class="number">4</span>);</span><br><span class="line"></span><br><span class="line">            <span class="keyword">int</span> len = row*col;</span><br><span class="line">            <span class="keyword">double</span> data[][] = <span class="keyword">new</span> <span class="keyword">double</span>[size][len];</span><br><span class="line">            <span class="keyword">byte</span>[] bufBytes = <span class="keyword">new</span> <span class="keyword">byte</span>[len];</span><br><span class="line">            <span class="keyword">int</span> idx = <span class="number">16</span>;</span><br><span class="line">           <span class="comment">// int n = 0;</span></span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i =<span class="number">0</span>;i &lt; size; i++)&#123;</span><br><span class="line">                bufIns.read(bufBytes,<span class="number">0</span>,len);</span><br><span class="line">                <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>; (j) &lt; bufBytes.length; j++)&#123;</span><br><span class="line">                    data[i][j] = ((<span class="keyword">double</span>)byte2Int2(bufBytes,j))/<span class="number">255.0</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> data;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">double</span> dt[][] = &#123;&#125;;</span><br><span class="line">        <span class="keyword">return</span> dt;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>可以发现，这里我们做了feature scalling， 把读到的没个像素的数值除以255. 就可以得到颜色的灰度。把数值控制在0-1之间。</p>
<p>再来看看读取这些数据的最终结果的数据，也就识别后需要比对的数据 </p>
<p>[offset] [type]          [value]          [description]<br>0000     32 bit integer  0x00000801(2049) magic number (MSB first)<br>0004     32 bit integer  60000            number of items<br>0008     unsigned byte   ??               label<br>0009     unsigned byte   ??               label<br>……..<br>xxxx     unsigned byte   ??               label</p>
<p>The labels values are 0 to 9.</p>
<p>这里从第三个字节开始就是label，数值从0-9</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">double</span>[][] readLabelFromFile(String fileName) <span class="keyword">throws</span> Exception&#123;</span><br><span class="line">       FileInputStream fin = <span class="keyword">new</span> FileInputStream(fileName);</span><br><span class="line">       <span class="keyword">if</span>(fin != <span class="keyword">null</span>) &#123;</span><br><span class="line">           BufferedInputStream bufIns = <span class="keyword">new</span> BufferedInputStream(fin);</span><br><span class="line">           <span class="keyword">byte</span>[] header = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">8</span>];</span><br><span class="line">           bufIns.read(header,<span class="number">0</span>,<span class="number">8</span>);</span><br><span class="line">           <span class="keyword">int</span> magic = byte2Int(header,<span class="number">0</span>);</span><br><span class="line">           <span class="keyword">int</span> size = byte2Int(header,<span class="number">4</span>);</span><br><span class="line">           <span class="keyword">byte</span>[] y= <span class="keyword">new</span> <span class="keyword">byte</span>[size];</span><br><span class="line">           bufIns.read(y,<span class="number">0</span>,size);</span><br><span class="line">           <span class="keyword">double</span> data[][] = <span class="keyword">new</span> <span class="keyword">double</span>[size][<span class="number">10</span>];</span><br><span class="line">           <span class="keyword">for</span>(<span class="keyword">int</span> i =<span class="number">0</span>;i &lt; size; i++)&#123;</span><br><span class="line">               <span class="keyword">int</span> label = (<span class="keyword">int</span>)y[i]&amp;<span class="number">0xff</span>;</span><br><span class="line">               <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>;  j&lt; <span class="number">10</span> ;j++) &#123;</span><br><span class="line">                   <span class="keyword">if</span>(j==label) &#123;</span><br><span class="line">                       data[i][j] = <span class="number">1</span>;</span><br><span class="line">                   &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                       data[i][j] = <span class="number">0</span>;</span><br><span class="line">                   &#125;</span><br><span class="line">               &#125;</span><br><span class="line">           &#125;</span><br><span class="line">           <span class="keyword">return</span> data;</span><br><span class="line"></span><br><span class="line">       &#125;</span><br><span class="line">       <span class="keyword">double</span> df[][] = &#123;&#125;;</span><br><span class="line">       <span class="keyword">return</span> df;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>
<p>把读取的数据按照行来存放，每一行是一张图片，这就是在java中需要转置的原因。</p>
<h1 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h1><p>正则化是在过拟合的时候使用。什么叫过拟合呢？ 就是对样本数据学习得很好，但是对于测试数据，就有很大偏差。</p>
<p>这时候我们可以考虑正则化。通俗的来说，正则化就是减少哪些权重低，但是变化快的因素。也就是“惩罚”这些参数。</p>
<p>我们来看看如何运用到深度学习。请参考理论部分。还记得正则化的最终推论，在改变权重的时候，对权重做了一个处理。</p>
<p>$$<br>(1-\frac{k\lambda}{n})<br>$$</p>
<p>这里k是学习速率，$\lambda$是正则化因子，n是 样本个数。从这里也可以看出，如果样本个数比较多，那么这个因子就接近1，也就是改变不大，也就是说，样本数量足够多，我们其实可以省略正则化。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">updateMiniBatch</span><span class="params">(TrainingData trainingMiniData, <span class="keyword">double</span> eta, <span class="keyword">double</span> lambda, <span class="keyword">double</span> n)</span> </span>&#123;</span><br><span class="line">        Matrix input = trainingMiniData.getInput();</span><br><span class="line">        Matrix output = trainingMiniData.getOutput();</span><br><span class="line">        Parameter params = backprop(input, output);</span><br><span class="line">        <span class="keyword">double</span> len = (<span class="keyword">double</span>) trainingMiniData.getSize();</span><br><span class="line">        <span class="comment">//after back propagation, update the parameters.</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="keyword">this</span>.sizes.length - <span class="number">1</span>; i++) &#123;</span><br><span class="line">            <span class="keyword">this</span>.bias[i] = <span class="keyword">this</span>.bias[i].subtract(params.getBias()[i].colSum().multiply(eta / len));</span><br><span class="line">            <span class="keyword">this</span>.weights[i] = <span class="keyword">this</span>.weights[i].multiply(<span class="number">1</span> - (eta * lambda) / n).subtract(params.getWeights()[i].multiply</span><br><span class="line">                    (eta / len));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>需要注意的是，偏置不需要正则化。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>如果理论熟悉了，在编码方面，依然会有一些细节要注意，一定要弄清楚各个数值。最后超参数是一个有趣的话题。学习速率，正则化的$\lambda$ 值，模型层次以及每一层的选择，以及批量大小这些都可以自己尝试。</p>
<p>最后还有一些优化可以尝试，比如更好的初始化参数，例如使用 均值为0，标准差为 $\frac{1}{\sqrt(n)}$  的方式初始化权重。这样使得我们的分布更胖一些，学习起来不会很快就饱和了。</p>
<p>如果你的编码正确，正确率在98%以上是没问题的。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.mindincode.com/2020/12/09/深度学习-理论/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Shaoxin Yin">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xin's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/12/09/深度学习-理论/" itemprop="url">深度学习 Step By Step (一，理论篇)</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-12-09T15:02:00+08:00">
                2020-12-09
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习-DNN/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习 DNN</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>一步一步理解深度学习，并通过编程语言实现。从模型到算法推导，深刻理解深度学习的思想。</p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2020/12/09/深度学习-理论/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.mindincode.com/2019/11/12/dht/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Shaoxin Yin">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xin's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/11/12/dht/" itemprop="url">Kademlia&#58; A Peer-to-peer Information System Based on the XOR Metric</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-11-12T11:57:26+08:00">
                2019-11-12
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/DHT-Peer-to-peer-XOR-Kademlia/" itemprop="url" rel="index">
                    <span itemprop="name">DHT Peer-to-peer XOR Kademlia</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <center>Petar Maymounkov and David Mazieres</center>

<center> &#123;petar, dm&#125;@cs.nyu.edu</center><br><center><a href="http://kademlia.scs.cs.nyu.edu" target="_blank" rel="noopener">http://kademlia.scs.cs.ny.edu</a></center>

<center>New York University</center>

<center><br>Abstract. We describe a peer-to-peer distributed hash table with provable consistency and performance in a fault-prone environment. Our system routes queries and locates nodes using a novel XOR-based metric toplogy that simplifies the algorithm and facilitates our proof. The topology has the property that every message exchanged conveys or reinforces useful contact information. The system exploits this information to send parallel, asynchronous query messages that tolerate node failures without imposing timeout delays on Users.<br><center><br><br><center><br> 我们描述了一种点对点的，可在易出错环境可证明，一致性和高性能的点对点的分布式哈希表。我们的系统使用一种新的基于XOR（异或）的拓扑度量来路由查询和定位节点，这种拓扑度量简化了算法并且使得证明更容易。这种拓扑有这样一种属性，每一条交换信息都传达或者增加了有用的连接信息。 系统利用这些信息并行异步的发送查询请求消息，这些消息可以容忍节点失败，而不会把超时延时强加于用户。<br></center></center></center>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2019/11/12/dht/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.mindincode.com/2019/04/22/概率-6-累计分布函数与质量函数/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Shaoxin Yin">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xin's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/22/概率-6-累计分布函数与质量函数/" itemprop="url">概率-累积分布函数CDF与质量分布函数PMF</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-22T20:16:50+08:00">
                2019-04-22
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/概率/" itemprop="url" rel="index">
                    <span itemprop="name">概率</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>什么是累计分布函数？他有什么用呢？<br>上一节讲了随机变量，这里我们继续沿用这个概念来说明累积分布函数。</p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2019/04/22/概率-6-累计分布函数与质量函数/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.mindincode.com/2019/04/22/概率-7-离散随机分布/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Shaoxin Yin">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xin's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/22/概率-7-离散随机分布/" itemprop="url">概率之离散随机分布</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-22T20:10:12+08:00">
                2019-04-22
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/概率/" itemprop="url" rel="index">
                    <span itemprop="name">概率</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>相同的实验模型有相同的概率模型，了解概率分布，就能模拟事件的发生运作方式。</p>
<p>接下来就是几种常见模型的分析。</p>
<h1 id="离散概率分布-Discrete-Probability-Distributions"><a href="#离散概率分布-Discrete-Probability-Distributions" class="headerlink" title="离散概率分布(Discrete Probability Distributions)"></a>离散概率分布(Discrete Probability Distributions)</h1><h2 id="Bernoulli-分布"><a href="#Bernoulli-分布" class="headerlink" title="Bernoulli 分布"></a>Bernoulli 分布</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1次实验，2种结果,在意某结果是否发生 -&gt; Bernoulli 概率分布</span><br></pre></td></tr></table></figure>
<ul>
<li>PMF: 若试验成功概率是 p ,一次实验， X表示成功次数</li>
</ul>
<p>$P_X(x): X~Bernoulli(p)$</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">   1-p     p</span><br><span class="line">    |      |</span><br><span class="line">    |      |</span><br><span class="line">----|------|--</span><br><span class="line">    0      1</span><br></pre></td></tr></table></figure>
<p>$$<br>p_X(x)=\begin{cases}<br>p,  &amp;x=1 \\<br>1-p,  &amp;x=0 \\<br>0,  &amp;otherwise<br>\end{cases}<br>$$</p>
<ul>
<li>CDF<br>$<br>F_X(x) = \sum\limits_{n=-\infty}^{|x|}p_X(x)<br>$</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">                    |-------|---</span><br><span class="line">                    | p     |</span><br><span class="line">             |------|-----  | 1</span><br><span class="line">             |  1-p         |</span><br><span class="line">-------------|------|-------|----</span><br><span class="line">             0      1</span><br></pre></td></tr></table></figure>
<p>$<br>F_x(x) = \begin{cases}<br>0, &amp;x &lt; 0, \\<br>0.4,  &amp;0\leq x &lt; 1, \\<br>1,  &amp;x\geq 1<br>\end{cases}<br>$</p>
<h2 id="Binomial-概率分布"><a href="#Binomial-概率分布" class="headerlink" title="Binomial 概率分布"></a>Binomial 概率分布</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">做N次实验，1个几率， 在意N次实验出现某结果k次的概率 -&gt; Binomial概率分布</span><br></pre></td></tr></table></figure>
<ul>
<li>PMF 若试验成功概率为p ,做n次实验，X表示成功次数</li>
</ul>
<p>$P_X(x)$:——— X-BIN(n,p)</p>
<p>$P(X=x) $<br>$=\tbinom{n}{x}P^x(1-p)^{n-x}$</p>
<p>成功 = x<br>失败 = n-x</p>
<ul>
<li>CDF<br>$F_X(x) = \sum\limits_{n=-\infty}^{|x|}p_X(x)$<br>$=\sum\limits_{m=-\infty}^{|x|}\tbinom{n}{m}\cdot p^m \cdot (1-p)^{n-m}$</li>
</ul>
<h2 id="Uniform-概率分布"><a href="#Uniform-概率分布" class="headerlink" title="Uniform 概率分布"></a>Uniform 概率分布</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1 次实验， n 种B结果， 个结果概率均等。</span><br><span class="line">在意某结果发生否 -&gt; Uniform 概率分布</span><br></pre></td></tr></table></figure>
<p>与Bernoulli分布不一样的是，Bernoulli只有2个结果,并且这些机会是均等的。</p>
<p>例子： 丢骰子。</p>
<ul>
<li>PMF</li>
</ul>
<p>如果X等于 a, a+1, …, b的概率均等</p>
<p>$P_X(x)$        X~UNIF(a,b)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1/(b-a+1) 1/(b-a+1)  1/(b-a+1)</span><br><span class="line">    |      |     |       |</span><br><span class="line">    |      |     |       | </span><br><span class="line">----|------|-----|-------|-</span><br><span class="line">    a     a+1    ...     b</span><br></pre></td></tr></table></figure>
<p>$p_X(x)=\begin{cases}<br>\frac{1}{b-a+1}, x = a, a+1, … , b \\<br>0, \quad\quad\quad otherwise.<br>\end{cases}<br>$</p>
<ul>
<li>CDF</li>
</ul>
<p>$F_X(x) = \sum\limits_{n=-\infty}^{|x|}p_X(x)$</p>
<p>$F_X(x)=\begin{cases}<br>0, \quad\quad\quad x &lt; a, \\<br>\frac{[x]-a+1}{b-a+1}, \quad a \leq x &lt; b,\\<br>1 , \quad\quad\quad x \geq b<br>\end{cases}<br>$</p>
<h2 id="Geometric-概率分布"><a href="#Geometric-概率分布" class="headerlink" title="Geometric 概率分布"></a>Geometric 概率分布</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">实验中出现结果的概率已知，重复试验知道该结果出现为止。</span><br><span class="line">在意某结果第几次实验首次出现 -&gt; Geometric 概率分布</span><br></pre></td></tr></table></figure>
<p>例子：</p>
<ul>
<li>阿宅告白成功概率0.3， 不成功誓不休。问第5次告白成功的概率？</li>
<li>孙文革命成功概率0.1， 不成功誓不秀。问第11次成功的概率？</li>
<li>段誉打出六脉神剑的概率0.1， 他在10次才打出六脉神剑的概率？</li>
</ul>
<p>用最后一个例子来说明。要第10次才成功，那么，前9次失败</p>
<p>败 败 败 败 败 败 败 败 败 成</p>
<p>概率 = </p>
<p>$0.9\times0.9\times0.9\times0.9\times0.9\times0.9\times0.9\times0.9\times0.9\times0.1 = 0.9^9\times 0.1$</p>
<ul>
<li>PMF<br>若试验成功概率为p， 尝试成功为止，做了X次尝试</li>
</ul>
<p>$p_X(x):$   X–Geometric(p)</p>
<p>$p_X(x)=\begin{cases}<br>(1-p)^{x-1}\cdot p ,  x = 1,2,3 … \\<br>0 , \quad\quad\quad otherwise<br>\end{cases}<br>$</p>
<ul>
<li>CDF<br>$F_X(x) = \sum\limits_{n=-\infty}^{|x|}p_X(n)$<br>$=\begin{cases}<br>\sum\limits_{n=1}^{|x|}(1-p)^{n-1}p = p\cdot \frac{1-(1-p)^{|x|}}{1-(1-p)},   x \geq 1, \\<br>0, \quad\quad\quad\quad\quad, x&lt;1<br>\end{cases}<br>$</li>
</ul>
<p>$=\begin{cases}<br>1-(1-p)^|x| , x\geq1 \\<br>0, \quad\quad otherwise<br>\end{cases}<br>$</p>
<h2 id="Pascal概率分布"><a href="#Pascal概率分布" class="headerlink" title="Pascal概率分布"></a>Pascal概率分布</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">实验中出现某结果的概率已知， 重复试验至该结果出现k次为止， </span><br><span class="line">在一到底在第几次试验才结束 -&gt; Pascal 概率分布</span><br></pre></td></tr></table></figure>
<p>Ex</p>
<ul>
<li>段誉的六脉神剑如果成功5次，功力就会耗尽，打出的概率是0.1， 那么他第九次刚好功力耗尽的概率。</li>
</ul>
<p>解<br>  可能情况之一  败 成 败 成 败 成 败 成 成<br>            $p = 0.9 \times 0.1 \times 0.9 \times 0.1 \times 0.9 \times 0.1 x\times 0.1$<br>             $=0.9^4 \times 0.1^5$<br>  刚好第9次才成功5次的情况有几种？ $\tbinom{8}{4}\tbinom{1}{1} = \tbinom{8}{4}$</p>
<ul>
<li>PMF</li>
</ul>
<p>若实验成功概率为p， 成功k次便结束实验，在第X次实验才成功k次的概率？</p>
<p>$P_X(x)$   X–Pascal(k,p)</p>
<p>$p_X(x) = \begin{cases}<br>\tbinom{x-1}{k-1}(1-p)^{x-k}p^k, x = k, k+1, …\\<br>0, \quad\quad\quad\quad\quad otherwise<br>\end{cases}<br>$</p>
<ul>
<li>CDF</li>
</ul>
<p>$F_X(x) = P(X\leq x)$<br>$=P(第k次成功在第x次以前发生)$<br>$=P(在x次实验中 \geq k 次成功)$<br>$=P(Y\geq k), Y–BIN(x,p)$</p>
<p>Pascal又称作 Negative Binomal<br>Pascal小于k的几率，等于binomal大于等于k的几率。</p>
<h2 id="Poisson分布"><a href="#Poisson分布" class="headerlink" title="Poisson分布"></a>Poisson分布</h2><p>Ex</p>
<ul>
<li><p>夜宵店，晚上平均每小时有10个客人， 问晚上开店5小时，有60人光顾的概率？</p>
</li>
<li><p>某医院平均每小时2个婴儿出生，问2小时内出生5个婴儿的概率？</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">某结果出现的平均速度(rate：次数/时间)已知。问次序观察某段时间后，</span><br><span class="line">看到结果出现k次的概率-&gt;Poisson概率分布</span><br></pre></td></tr></table></figure>
</li>
<li><p>PMF<br>已知某事件发生速率为每单位时间 $\lambda$ 次，观察时间 T 为时间单位。 X 为观察时间内发生的事件次数则</p>
</li>
</ul>
<p>$X – POI(\lambda T)$</p>
<p>$p_X(x) = P(X=x) = e^{-\lambda T}\cdot \frac{(\lambda T)^x}{x!}$</p>
<p>$\mu = \lambda T, X–POI(\mu)\Rightarrow P_X(x) = e^{-\mu}\cdot\frac{\mu^x}{x!}$</p>
<ul>
<li>CDF</li>
</ul>
<p>$X-POI(\lambda T)$</p>
<p>$F_X(x) = \sum\limits_{n=-\infty}^{|x|}p_X(x)=\begin{cases}<br>\sum\limits_{n=-\infty}^{|x|}e^{-\mu}\cdot\frac{\mu ^n}{n!}, x = 0, 1, 2,…\\<br>0, \quad\quad\quad\quad\quad otherwise<br>\end{cases}<br>$</p>
<ul>
<li>Poisson怎么推出的？</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">       客人来      客人来      客人来</span><br><span class="line">        |         | |           |</span><br><span class="line">|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|</span><br><span class="line">                T</span><br></pre></td></tr></table></figure>
<p>將T切成長度為 $\delta T$  个极小段</p>
<p>$\delta T -&gt; 0 \Rightarrow 共有 n = \frac{T}{\delta_T} -&gt; \infty$ 个小段。<br>若发生速率为 $\lambda$ 次/分 。每个小段会发生的概率为 $p=\lambda\delta_T=\frac{\lambda T}{n}$</p>
<p>故T时间内发生的次数（客人来） $X-BIN(n,p) = BIN(n, \frac{\lambda T}{n})$</p>
<p>$\lim\limits_{\delta_T-&gt;0}p_X(x) = \lim\limits_{n-&gt;\infty}\frac{n!}{(n-x)!x!}(\frac{\lambda T}{n})^x(1-\frac{\lambda T}{n})^{n-x}$</p>
<p>$=\lim\limits_{n-&gt;\infty}\frac{n(n-1)…(n-x+1)}{X!}\frac{(\lambda T)^x}{n^x}(1-\frac{\lambda T}{n})^{n-x}$</p>
<p>$=\lim\limits_{n-&gt;\infty}\frac{1}{x!}\frac{n}{n}\frac{n-1}{n}…\frac{n-x+1}{n}(\lambda T)^x(1-\frac{\lambda T}{n})^n(1-\frac{\lambda T}{n})^{-x}$</p>
<p>$=\frac{(\lambda T)^x}{x!}\lim\limits_{n-&gt;\infty}(1-\frac{\lambda T}{n})^n$</p>
<p>$=\frac{(\lambda T)^x}{x!}e^{-\lambda T}$</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.mindincode.com/2019/04/22/概率-5-随机变量/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Shaoxin Yin">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xin's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/22/概率-5-随机变量/" itemprop="url">概率-随机变量</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-22T15:20:02+08:00">
                2019-04-22
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/概率/" itemprop="url" rel="index">
                    <span itemprop="name">概率</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>随机变量是什么？ 回忆废文兄发废文，我们要这么写<br> P(“你妈知道你在发废文吗”)=0.4<br> P(“见此ID必嘘”) = 0.2<br> P(“在五楼……”) = 0.1<br> P(“妈！我在这”) = 0.3</p>
<p>  P(“妈！我在这”) = 1 - P(“你妈知道你在发废文吗”) - P(“见此ID必嘘”) - P(“在五楼……”) </p>
<p> 有没有觉得有问题？ 那就是太啰嗦了！</p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2019/04/22/概率-5-随机变量/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.mindincode.com/2019/04/19/概率-4-常見概率/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Shaoxin Yin">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xin's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/19/概率-4-常見概率/" itemprop="url">概率-古典概率</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-19T17:36:02+08:00">
                2019-04-19
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/概率/" itemprop="url" rel="index">
                    <span itemprop="name">概率</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>生活中的一些例子，可以归纳出一些概率求取方法。<br>叶老师的“数数算几率”</p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2019/04/19/概率-4-常見概率/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.mindincode.com/2019/04/18/概率-3-条件概率/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Shaoxin Yin">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xin's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/18/概率-3-条件概率/" itemprop="url">概率-条件概率</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-18T14:36:02+08:00">
                2019-04-18
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/概率/" itemprop="url" rel="index">
                    <span itemprop="name">概率</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>生活中常常遇到很多事情已经发生，那么这些发生的事情对我们的决策有多少影响呢？<br>我们引入了条件概率。</p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2019/04/18/概率-3-条件概率/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.mindincode.com/2019/04/17/概率-2-公理性质/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Shaoxin Yin">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xin's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/17/概率-2-公理性质/" itemprop="url">概率-公理性质</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-17T11:36:02+08:00">
                2019-04-17
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/概率/" itemprop="url" rel="index">
                    <span itemprop="name">概率</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>数学的基石是公理，公理是不可证明的。<br>例如线性代数的8条公理 Ex  加法交换律  a + b  = b + a<br>通过公理，我们可以推出很多定理。<br>如果其他领域能够符合公理，那么之后的推论都可以应用。所以公理非常牛，我们来看看概率的公理</p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2019/04/17/概率-2-公理性质/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.mindincode.com/2019/04/16/概率-1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Shaoxin Yin">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xin's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/16/概率-1/" itemprop="url">概率-概念</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-16T15:36:02+08:00">
                2019-04-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/概率/" itemprop="url" rel="index">
                    <span itemprop="name">概率</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>我们都知道，抛一个硬币，落地上正面朝上的几率是50%， 而一个骰子落地面，是6点的几率呢？<br>这就不好说了，如果骰子是普通的，没有做过手脚的，我们会说这个几率是 六分之一，因为他有六个面啊。几率在生活中处处都会用到，但是我们如何通过数学来定义描述他呢？<br>由此引申出来的贝叶斯公式，概率分布，似然估计等概念在很多领域有广泛的应用。<br>现在我们跟随丙成老师的课，来走进几率。</p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2019/04/16/概率-1/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/header.jpg"
                alt="Shaoxin Yin" />
            
              <p class="site-author-name" itemprop="name">Shaoxin Yin</p>
              <p class="site-description motion-element" itemprop="description">A programmer's mind</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">20</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">10</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">20</span>
                  <span class="site-state-item-name">标签</span>
                
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/airuqixue" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="http://douban.com/people/airuqixue" target="_blank" title="豆瓣">
                      
                        <i class="fa fa-fw fa-globe"></i>豆瓣</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Shaoxin Yin</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
